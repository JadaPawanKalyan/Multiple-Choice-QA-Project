{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.layers import Input,LSTM,Bidirectional,Dense,Dropout,Flatten,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwz3MEMQaIBC"
   },
   "outputs": [],
   "source": [
    "# configuring tpu scope\n",
    "\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Lw6wu1GS0Mb",
    "outputId": "58cd5a0b-48d5-4dd9-8821-343a93db2978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWsqv16e2OAx"
   },
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "with open('train.json','rb') as f:\n",
    "  k=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO7ZztrF3oBw"
   },
   "outputs": [],
   "source": [
    "# creating multiple arrays for questions, answer-1, answer-2, answer-3, answer-4\n",
    "\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "d=[]\n",
    "q=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J--BxajD4C8O"
   },
   "outputs": [],
   "source": [
    "# Appending the answers in arrays\n",
    "\n",
    "for i in range(len(k)):\n",
    "  a.append(k[i]['correct_answer'])\n",
    "  b.append(k[i]['distractor1'])\n",
    "  c.append(k[i]['distractor2'])\n",
    "  d.append(k[i]['distractor3'])\n",
    "  q.append(k[i]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AyN3mrH4yd6"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kRYrDdH5ItX"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_6fSOIE5QKs"
   },
   "outputs": [],
   "source": [
    "# Initailizing the tokenizer\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ig-Qb3bt51eo"
   },
   "outputs": [],
   "source": [
    "# Converting all answers into a single string by seperating with <sep>\n",
    "\n",
    "s=[]\n",
    "for i in range(len(k)):\n",
    "  p=[a[i],b[i],c[i],d[i]]\n",
    "  shuffle(p)\n",
    "  s.append(' <sep> '.join(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4Gm0Tqd7bs-",
    "outputId": "7cf05ce6-e045-49d0-ec94-69cc3dc22521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(['<sep>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWfc2BN3TYaF"
   },
   "outputs": [],
   "source": [
    "# finding the encodings\n",
    "\n",
    "train_encodings=tokenizer(q,s,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-4qOSkzU2YT"
   },
   "outputs": [],
   "source": [
    "al=[]\n",
    "for i in range(len(k)):\n",
    "    s1=s[i].index(a[i])\n",
    "    s2=s1+len(a[i])\n",
    "    al.append((s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ya6CxW0c8WE9"
   },
   "outputs": [],
   "source": [
    "# function to find the token positions for the question-answering model\n",
    "\n",
    "def add_token_positions(encodings, al):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(k)):\n",
    "        start_positions.append(encodings.char_to_token(i, al[i][0],1))\n",
    "        end_positions.append(encodings.char_to_token(i,al[i][1]-1,1))\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length-1\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length-1\n",
    "    return start_positions,end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87U20buqWVBI"
   },
   "outputs": [],
   "source": [
    "# finding the start and end token by calling above function\n",
    "\n",
    "start,end=add_token_positions(train_encodings,al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBqTb-AyXo8x"
   },
   "outputs": [],
   "source": [
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m77CgqMMX3La"
   },
   "outputs": [],
   "source": [
    "# Transfer learning\n",
    "\n",
    "with tpu_strategy.scope():\n",
    "    model=TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-YtE1d2X5dX"
   },
   "outputs": [],
   "source": [
    "# Resizing Token Embeddings\n",
    "\n",
    "with tpu_strategy.scope():\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nS-Uv8V2YCYr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,LSTM,Bidirectional,Dense,Dropout,Flatten,Activation\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKXM-wbhYJKa"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xkkmW5tYR67"
   },
   "outputs": [],
   "source": [
    "# Converting lists to Numpy Arrays\n",
    "\n",
    "q=np.array(train_encodings['input_ids'])\n",
    "q1=np.array(train_encodings['attention_mask'])\n",
    "q2=np.array(train_encodings['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faqCpqrxZOqy"
   },
   "outputs": [],
   "source": [
    "# Converting lists to Numpy Arrays\n",
    "\n",
    "train_start=np.array(start)\n",
    "train_end=np.array(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4wJaM2hYLMz"
   },
   "outputs": [],
   "source": [
    "# Creating the architecture for our model\n",
    "\n",
    "with tpu_strategy.scope():\n",
    "  inp1=Input((121,),dtype='int32')\n",
    "  inp2=Input((121,),dtype='int32')\n",
    "  inp3=Input((121,),dtype='int32')\n",
    "  emb=model(inp1,attention_mask=inp2,token_type_ids=inp3)[0]\n",
    "  s1=Dense(1,use_bias=False)(emb)\n",
    "  s1=Flatten()(s1)\n",
    "  s1=Activation(keras.activations.softmax)(s1)\n",
    "  s2=Dense(1,use_bias=False)(emb)\n",
    "  s2=Flatten()(s2)\n",
    "  s2=Activation(keras.activations.softmax)(s2)\n",
    "  m=Model(inputs=[inp1,inp2,inp3],outputs=[s1,s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpZtCP3eY-8u"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "\n",
    "with tpu_strategy.scope():\n",
    "  m.compile(optimizer=keras.optimizers.SGD(learning_rate=2e-5),loss=['sparse_categorical_crossentropy','sparse_categorical_crossentropy'],metrics=['accuracy'],steps_per_execution=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZ45WHbjZWJ8",
    "outputId": "69c681f2-2c38-457b-d75e-50a81d804688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.8598 - activation_loss: 2.0909 - activation_1_loss: 1.7689 - activation_accuracy: 0.2286 - activation_1_accuracy: 0.2820\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.7684 - activation_loss: 2.0411 - activation_1_loss: 1.7273 - activation_accuracy: 0.2312 - activation_1_accuracy: 0.2808\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.6821 - activation_loss: 1.9879 - activation_1_loss: 1.6942 - activation_accuracy: 0.2422 - activation_1_accuracy: 0.2796\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.6128 - activation_loss: 1.9473 - activation_1_loss: 1.6655 - activation_accuracy: 0.2489 - activation_1_accuracy: 0.2776\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.5520 - activation_loss: 1.9147 - activation_1_loss: 1.6372 - activation_accuracy: 0.2522 - activation_1_accuracy: 0.2873\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.5028 - activation_loss: 1.8858 - activation_1_loss: 1.6170 - activation_accuracy: 0.2584 - activation_1_accuracy: 0.2864\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.4643 - activation_loss: 1.8612 - activation_1_loss: 1.6030 - activation_accuracy: 0.2627 - activation_1_accuracy: 0.2899\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.4179 - activation_loss: 1.8365 - activation_1_loss: 1.5814 - activation_accuracy: 0.2736 - activation_1_accuracy: 0.2897\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.3841 - activation_loss: 1.8103 - activation_1_loss: 1.5738 - activation_accuracy: 0.2732 - activation_1_accuracy: 0.2939\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 11s 62ms/step - loss: 3.3496 - activation_loss: 1.7867 - activation_1_loss: 1.5629 - activation_accuracy: 0.2776 - activation_1_accuracy: 0.2957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f97a1488450>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our model\n",
    "\n",
    "m.fit([q,q1,q2],[train_start,train_end],epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-USoOGi4c1OC"
   },
   "outputs": [],
   "source": [
    "# Compiling with different learning rate\n",
    "\n",
    "with tpu_strategy.scope():\n",
    "  m.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-5),loss=['sparse_categorical_crossentropy','sparse_categorical_crossentropy'],metrics=['accuracy'],steps_per_execution=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbD195yAcET_",
    "outputId": "9f7ce7c9-5717-49d7-e59f-321a71c387ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "183/183 [==============================] - 12s 66ms/step - loss: 0.0673 - activation_loss: 0.0343 - activation_1_loss: 0.0330 - activation_accuracy: 0.9877 - activation_1_accuracy: 0.9888\n",
      "Epoch 2/7\n",
      "183/183 [==============================] - 12s 66ms/step - loss: 0.0645 - activation_loss: 0.0325 - activation_1_loss: 0.0320 - activation_accuracy: 0.9884 - activation_1_accuracy: 0.9890\n",
      "Epoch 3/7\n",
      "183/183 [==============================] - 12s 66ms/step - loss: 0.0630 - activation_loss: 0.0320 - activation_1_loss: 0.0310 - activation_accuracy: 0.9889 - activation_1_accuracy: 0.9902\n",
      "Epoch 4/7\n",
      "183/183 [==============================] - 12s 66ms/step - loss: 0.0453 - activation_loss: 0.0232 - activation_1_loss: 0.0221 - activation_accuracy: 0.9932 - activation_1_accuracy: 0.9937\n",
      "Epoch 5/7\n",
      "183/183 [==============================] - 12s 65ms/step - loss: 0.0493 - activation_loss: 0.0260 - activation_1_loss: 0.0233 - activation_accuracy: 0.9915 - activation_1_accuracy: 0.9919\n",
      "Epoch 6/7\n",
      "183/183 [==============================] - 12s 66ms/step - loss: 0.0492 - activation_loss: 0.0251 - activation_1_loss: 0.0241 - activation_accuracy: 0.9932 - activation_1_accuracy: 0.9934\n",
      "Epoch 7/7\n",
      "183/183 [==============================] - 12s 66ms/step - loss: 0.0443 - activation_loss: 0.0220 - activation_1_loss: 0.0223 - activation_accuracy: 0.9922 - activation_1_accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f96ab877790>"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with new learning rate\n",
    "\n",
    "m.fit([q,q1,q2],[train_start,train_end],epochs=7,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyOezlr6hWDt"
   },
   "outputs": [],
   "source": [
    "# Function to find the answer\n",
    "\n",
    "def find_answer(context,question):\n",
    "  enc=tokenizer(question,context,padding='max_length',max_length=121)\n",
    "  k = np.array([enc['input_ids']])\n",
    "  k1 = np.array([enc['attention_mask']])\n",
    "  k2 = np.array([enc['token_type_ids']])\n",
    "  res=m([k,k1,k2])\n",
    "  start=np.argmax(res[0].numpy()[0])\n",
    "  end=np.argmax(res[1].numpy()[0])\n",
    "  return tokenizer.decode(k[0][start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EvNmQf4iJ-1"
   },
   "outputs": [],
   "source": [
    "# Validation data\n",
    "\n",
    "with open('valid.json','rb') as f:\n",
    "  k1=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5egA2CWi5Sc"
   },
   "outputs": [],
   "source": [
    "# Encoding the validation data\n",
    "\n",
    "a1=[]\n",
    "b1=[]\n",
    "c1=[]\n",
    "d1=[]\n",
    "q1=[]\n",
    "\n",
    "for i in range(len(k1)):\n",
    "  a1.append(k1[i]['correct_answer'])\n",
    "  b1.append(k1[i]['distractor1'])\n",
    "  c1.append(k1[i]['distractor2'])\n",
    "  d1.append(k1[i]['distractor3'])\n",
    "  q1.append(k1[i]['question'])\n",
    "\n",
    "s1=[]\n",
    "for i in range(len(k1)):\n",
    "  p=[a1[i],b1[i],c1[i],d1[i]]\n",
    "  shuffle(p)\n",
    "  s1.append(' <sep> '.join(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pvu7aFj9jrkz"
   },
   "outputs": [],
   "source": [
    "# Index to the question\n",
    "\n",
    "i=75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lNVYaRKyjWpp",
    "outputId": "37ca1035-1888-4aea-b36f-521d9c74ccc9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'What is caused by the reaction of nonmetal oxides with water in the atmosphere?'"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting a particular question\n",
    "\n",
    "q1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7xuF2OqljYDq",
    "outputId": "ff503a40-5ddd-4ff3-e011-f74c493ce88b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ozone rain <sep> yellow rain <sep> carbon rain <sep> acid rain'"
      ]
     },
     "execution_count": 150,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple choices of that question\n",
    "\n",
    "s1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wKdvzOpejY9q",
    "outputId": "34b21448-ce50-40c3-fd20-54fce36591bb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'acid rain'"
      ]
     },
     "execution_count": 151,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct answer for that question\n",
    "a1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Puc8vjuGjjUK",
    "outputId": "a1fa6aa1-279a-433a-b4bb-2f5b57035462"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'acid rain'"
      ]
     },
     "execution_count": 152,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted answer\n",
    "find_answer(s1[i],q1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that that both answers are same here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-E0YAJpjoc2"
   },
   "outputs": [],
   "source": [
    "# Saving the model to reuse later\n",
    "\n",
    "save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "m.save_weights('/content/drive/MyDrive/mcq model/model_weights', options=save_locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqK5vJD7mUES"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "mcq question answering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
